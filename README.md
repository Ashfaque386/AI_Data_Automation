# Enterprise Data Operations Platform

Production-grade data operations console combining Excel-level manipulation, SQL querying, and AI-assisted automation.

## ğŸš€ Quick Start (Docker)

### Prerequisites
- **Docker Desktop** installed
- **PostgreSQL** running on host (port 5432)
- **Ollama** running on host (port 11434, optional for AI)

### Setup & Run

```powershell
# 1. Start Application
docker-compose up --build

# 2. Access Application
# Open http://localhost:5173
# You will be redirected to the Login page.

# 3. Login
# Default Credentials:
# Email: admin@example.com
# Password: admin123

# 4. Configure System
# After login, you will land on the Home Dashboard.
# - Database: Click "Settings" to configure your PostgreSQL connection.
# - AI: Select your preferred AI model from the "Settings" page.
```

**âœ¨ New Features:**
- **Dynamic Setup**: Configure your database and AI models directly from the UI.
- **Login First**: Secure by default - authentication required immediately.

## ğŸ”„ Application Maintenance

### Restarting the Application
To apply configuration changes or restart services:

```powershell
# 1. Stop all services
docker-compose down

# 2. Start services (and rebuild if code changed)
docker-compose up -d --build

# 3. Restart a specific service (e.g., backend)
docker-compose restart backend
```

### Resetting Data
To completely reset the application ( WARNING: Deletes all data):

```powershell
docker-compose down -v
```

## ğŸ“– Documentation

- **[Docker Setup Guide](DOCKER_SETUP.md)** - Detailed Docker instructions and troubleshooting
- **[API Documentation](http://localhost:8000/docs)** - Interactive API docs (when running)

## ğŸ¯ Features

### Core Capabilities
- **Multi-format file upload**: Excel (multi-sheet), CSV, JSON, Parquet
- **SQL query execution**: DuckDB-powered analytics engine
- **Excel formulas**: 30+ compatible functions (SUM, VLOOKUP, IF, etc.)
- **Data export**: Excel, CSV, JSON, Parquet formats
- **AI assistance**: Natural language to SQL, formula suggestions, data quality checks
- **Enterprise security**: JWT auth, RBAC, audit logging, column-level permissions

### Tech Stack

**Backend**:
- FastAPI 0.109 + Python 3.11
- PostgreSQL (metadata) + DuckDB (analytics)
- SQLAlchemy 2.0 ORM
- Ollama integration (local LLM)

**Frontend**:
- React 18 + TypeScript 5
- Vite 5 build system
- TanStack Query + Zustand
- Enterprise dark theme UI

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Host Machine                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PostgreSQL  â”‚    â”‚   Ollama     â”‚  â”‚
â”‚  â”‚  :5432       â”‚    â”‚   :11434     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â–²                    â–²          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Docker Containers                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Backend    â”‚â”€â”€â”€â–¶â”‚  Frontend    â”‚   â”‚
â”‚  â”‚  FastAPI    â”‚    â”‚  React+Vite  â”‚   â”‚
â”‚  â”‚  :8000      â”‚    â”‚  :5173       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/          # API routes
â”‚   â”‚   â”œâ”€â”€ core/         # Auth, RBAC, Audit
â”‚   â”‚   â”œâ”€â”€ models/       # Database models
â”‚   â”‚   â”œâ”€â”€ services/     # Business logic
â”‚   â”‚   â””â”€â”€ main.py       # FastAPI app
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ init_db.py    # Database initialization
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/   # React components
â”‚       â”œâ”€â”€ pages/        # Page layouts
â”‚       â”œâ”€â”€ services/     # API client
â”‚       â””â”€â”€ store/        # State management
â”œâ”€â”€ docker-compose.yml    # Container orchestration
â”œâ”€â”€ Dockerfile.backend    # Backend container
â”œâ”€â”€ Dockerfile.frontend   # Frontend container
â””â”€â”€ .env.docker          # Environment template
```

## ğŸ”§ Configuration

Edit `.env` file:

```env
# PostgreSQL on host
DATABASE_URL=postgresql://postgres:YOUR_PASSWORD@host.docker.internal:5432/dataops

# Ollama on host (optional)
OLLAMA_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama2
AI_ENABLED=true

# Security
SECRET_KEY=your-secure-random-key-here
DEBUG=true
```

## ğŸ³ Docker Commands

```bash
# Start services
docker-compose up -d

# View logs
docker-compose logs -f

# Restart a service
docker-compose restart backend

# Stop services
docker-compose down

# Rebuild after code changes
docker-compose up --build
```

## ğŸ” Default Credentials

- **Email**: admin@example.com
- **Password**: admin123

âš ï¸ **Change immediately in production!**

## ğŸ¤– AI Features

Requires Ollama running on host:

```bash
# Verify Ollama
curl http://localhost:11434/api/version

# Pull model
ollama pull llama2
```

AI capabilities:
- Natural language â†’ SQL conversion
- Excel formula suggestions
- Data quality issue detection
- Column type classification

## ğŸš¦ Usage

1. **Upload Data**: Click "Data Sources" â†’ "+ Upload" â†’ Select Excel/CSV file
2. **View Data**: Select dataset from sidebar to view in grid
3. **Run SQL**: Click "SQL Workspace" â†’ Enter query â†’ Ctrl+Enter
4. **Export**: Select dataset â†’ Export to Excel/CSV/JSON

## ğŸ” API Endpoints

Access interactive docs at `http://localhost:8000/docs`

- `/api/auth/*` - Authentication (login, register, refresh)
- `/api/datasets/*` - Dataset management and data grid
- `/api/sql/*` - SQL execution and query history
- `/api/export/*` - Data export (Excel, CSV, JSON, Parquet)
- `/api/ai/*` - AI-assisted operations
- `/api/users/*` - User and role management

## ğŸ› ï¸ Troubleshooting

**Backend can't connect to PostgreSQL:**
```powershell
# Verify PostgreSQL 18 is running (Windows)
& "C:\Program Files\PostgreSQL\18\bin\psql.exe" --version

# Check connection to your database
& "C:\Program Files\PostgreSQL\18\bin\psql.exe" -U postgres -d your_db_name -c "SELECT 1"
```

**Frontend can't reach backend:**
```powershell
# Check backend health
curl http://localhost:8000/health
```

**Port conflicts:**
```powershell
# Stop containers
docker-compose down

# Check what's using ports
netstat -ano | findstr :8000
netstat -ano | findstr :5173

# Or change ports in docker-compose.yml
```

See [DOCKER_SETUP.md](DOCKER_SETUP.md) for detailed troubleshooting.

## ğŸ“Š Data Persistence

Data persists in host directories:
- `./uploads/` - Uploaded files
- `./data/` - DuckDB analytics database

## ğŸš€ Production Deployment

1. Update `.env`:
   - Set `DEBUG=false`
   - Use strong `SECRET_KEY`
   - Configure production database
   - Set appropriate CORS origins

2. Add reverse proxy (Nginx/Traefik)
3. Enable HTTPS/SSL
4. Set resource limits in docker-compose.yml

## ğŸ“ License

Enterprise Data Operations Platform - Internal Use

---

**Need help?** Check [DOCKER_SETUP.md](DOCKER_SETUP.md) for detailed instructions.

#### 1. Setup PostgreSQL Database
```bash
# Create database
createdb dataops

# Or via psql
psql -U postgres
CREATE DATABASE dataops;
```

#### 2. Backend Setup
```bash
cd backend

# Create virtual environment
python -m venv venv
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Create .env file from template
copy app\.env.example app\.env
# Edit app\.env with your PostgreSQL credentials

# Run backend
uvicorn app.main:app --reload --port 8000
```

#### 3. Frontend Setup
```bash
cd frontend

# Install dependencies
npm install

# Run frontend
npm run dev
```

#### 4. Access the Application
- **Frontend**: http://localhost:5173
- **API Docs**: http://localhost:8000/docs
- **Default Login**: admin@example.com / admin123

### Option 2: Docker Compose

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ backend/              # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/         # API routes
â”‚   â”‚   â”œâ”€â”€ core/        # Auth, RBAC, Audit
â”‚   â”‚   â”œâ”€â”€ models/      # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas/     # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ services/    # Business logic
â”‚   â”‚   â”œâ”€â”€ config.py    # Configuration
â”‚   â”‚   â”œâ”€â”€ database.py  # DB connections
â”‚   â”‚   â””â”€â”€ main.py      # FastAPI app
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/            # React + TypeScript
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/  # React components
â”‚   â”‚   â”œâ”€â”€ pages/       # Page layouts
â”‚   â”‚   â”œâ”€â”€ services/    # API client
â”‚   â”‚   â”œâ”€â”€ store/       # State management
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â””â”€â”€ package.json
â””â”€â”€ docker-compose.yml
```

## ğŸ¯ Features

### âœ… Implemented
- **Authentication & Authorization**: JWT-based auth with RBAC
- **File Ingestion**: Excel, CSV, JSON multi-format support
- **SQL Engine**: DuckDB-powered query execution
- **Formula Engine**: 30+ Excel-compatible functions
- **Data Export**: Excel, CSV, JSON, Parquet
- **AI Integration**: Ollama-based NLâ†’SQL, formula suggestions
- **Audit Logging**: Complete operation tracking
- **Enterprise UI**: Dark theme admin console

### ğŸ“ Key Capabilities
- Multi-sheet Excel upload with schema detection
- Real-time SQL query execution & optimization
- Column-level permissions
- Dataset versioning
- Query history & favorites
- Data quality suggestions (AI)

## ğŸ”§ Configuration

### Backend (.env)
```env
DATABASE_URL=postgresql://postgres:your_password@localhost:5432/dataops
SECRET_KEY=your-secret-key
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama2
```

### Frontend (environment)
```env
VITE_API_URL=http://localhost:8000
```

## ğŸ“š API Documentation

Access Swagger UI at `http://localhost:8000/docs` for:
- Authentication endpoints
- Dataset management
- SQL execution
- AI-assisted operations
- Export functionality

## ğŸ¨ Tech Stack

**Backend**:
- FastAPI 0.109
- SQLAlchemy 2.0
- DuckDB 0.9
- PostgreSQL
- Pydantic v2
- Ollama (AI)

**Frontend**:
- React 18
- TypeScript 5
- Vite 5
- TanStack Query
- Zustand
- Axios

## ğŸ” Default Credentials

First time setup creates a default admin user:
- **Email**: admin@example.com
- **Password**: admin123

**âš ï¸ Change these credentials immediately in production!**

## ğŸ“Š Database Schema

The platform uses PostgreSQL for metadata and DuckDB for analytics:
- **Users, Roles, Permissions**: RBAC system
- **Datasets, Columns, Versions**: Data catalog
- **Audit Logs**: Complete operation history
- **Query History**: SQL query versioning

## ğŸ¤– AI Features (Ollama Required)

Make sure Ollama is running locally:
```bash
# Check Ollama is running
curl http://localhost:11434/api/version

# Pull llama2 model if needed
ollama pull llama2
```

AI features include:
- Natural language to SQL conversion
- Excel formula suggestions
- Data quality issue detection
- Column type classification

## ğŸ³ Production Deployment

1. Update `.env` with production values
2. Set `DEBUG=false`
3. Use strong `SECRET_KEY`
4. Configure PostgreSQL with production credentials
5. Set up SSL/TLS termination
6. Deploy via Docker Compose or Kubernetes

## ğŸ“– Additional Documentation

For detailed information on specific components:
- See `implementation_plan.md` for architecture details
- Check `/docs` endpoint for API documentation
- Review code comments for implementation details
